---
title: "P8105 Data Science I Homework 6"
author: Olivia Wang (hw2852)
output: github_document
date: "2022-12-03"
---

In preparation for the problems below, we will load the following libraries: 

```{r load_libraries}
library(tidyverse)
library(readxl)
library(dplyr)
library(modelr)
```

# Problem 1



# Problem 2

## 2.1 Homicide Data Import and Cleaning

Let us begin by importing the CSV file containing _Washington Post's_ homicide data downloaded from GitHub, and applying the `clean_names` function. Next, we can create a new `city_state` variable (e.g. "Baltimore, MD") by joining the existing city and state variables using the `paste` command, and a new binary `homicide_solved` variable indicating whether a homicide is solved. The `victim_age` variable previously read as a character variable is transformed into a numeric variable. Finally, we filtered the data to exclude information from Dallas, TX, Phoenix, AZ, Kansas City, MD, and Tulsa, AL, and to only include victims whose reported race was White or Black. 

```{r}
homicide_data = 
  read_csv("./homicide-data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(city_state = as.character(paste(city, state, sep = ", ")), 
         homicide_solved = ifelse(disposition == "Closed by arrest", 1, 0), 
         victim_age = as.numeric(victim_age)) %>% 
  filter(!(city_state %in% c("Dallas, TX", "Phoeniz, AZ", "Kansas City, MO", "Tulsa, AL")), 
         victim_race %in% c("White", "Black"))
```

## 2.2 Homicide Data Analysis: Odds Ratios & 95% CIs

#### _Solved Homicides Comparing Male & Female Victims in Baltimore, MD_

Below we use the `glm` function to estimate the odds ratio of solved homicides comparing male to female victims, specifically in Baltimore, MD, adjusting for age and race. The arguments for the `glm` function indicate that the `homicide_solved` variable is the outcome of interest, and `victim_age`, `victim_sex` and `victim_race` are the predictors.

The output generated from the `glm` function is then saved as an R object. The `broom::tidy()` function was applied to tidy the output, and the log odds ratios, odds ratios, and p-value corresponding to each term in the regression model were pulled and tabulated. In the final step, the `confint` function was applied to the output generated from the `glm` function to generate the 95% confidence intervals surrounding the odds ratios. 

```{r}
homicide_data_df = homicide_data %>% 
  filter(city_state == "Baltimore, MD")

glm_homicide_baltimore = 
  homicide_data_df %>% 
  glm(homicide_solved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())

glm_homicide_baltimore %>%
  broom::tidy() %>%
  mutate(odds_ratio = exp(estimate), 
         lower_CI = exp(estimate - 1.96*std.error), 
         upper_CI = exp(estimate + 1.96*std.error)) %>%
  select(term, odds_ratio, lower_CI, upper_CI) %>% 
  filter(term == "victim_sexMale") %>% 
  knitr::kable(col.names = c('Term', 'Odds Ratio', 'Lower 95% CI Limit', 'Upper 95% CI Limit'), digits = 3)
```

In Baltimore, MD, the odds ratio of solving homicides comparing male victims to female victims, adjusting for age and race, was 0.456. We are 95% confident that the true odds ratio of solving homicides comparing male and female victims, adjusting for age and race, lies between 0.340 and 0.612.

#### _Solved Homicides Comparing Male & Female Victims in All Cities_

We will now apply the `glm` function to all cities in the data set. This process involves first creating a new `glm_homicide` function, which applies the `glm` function to selected inputs. We then use the `select` function to reorder the columns in the data frame to have `city_state` appear first, as the function will be mapped to each unique `city_state`. The city-level homicide data will then be nested using the `nest` function to generate list columns for city-level homicide counts, and the `glm_homicide` function will be mapped to each tibble using `purrr::map`. Finally, we apply the `unnest` function to generate the city-specific odds ratio and 95% CIs. 

```{r}
glm_homicide = function(homicide_data) {
  glm(homicide_solved ~ victim_age + victim_sex + victim_race, data = homicide_data, family = binomial()) %>% 
  broom::tidy() %>%
  mutate(odds_ratio = exp(estimate), 
         lower_CI = exp(estimate - 1.96*std.error), 
         upper_CI = exp(estimate + 1.96*std.error)) %>%
  select(term, odds_ratio, lower_CI, upper_CI) %>% 
  filter(term == "victim_sexMale")
}

homicide_data_analysis = homicide_data %>% 
  select(city_state, everything()) %>% 
  nest(data = uid:homicide_solved) %>% 
  mutate(glm_homicide_output = purrr::map(.x = data, ~ glm_homicide(.x))) %>% 
  unnest(cols = glm_homicide_output)
```

#### _Plotting City-Specific Solved Homicides Comparing Male & Female Victims_

using the generated output from the analysis above, we will plot the city-level odds ratio estimates of unsolved homicides comparing male to female victims and corresponding 95% CIs using `ggplot`. In addition to plotting the OR estimates using `geom_point`, the 95% confidence intervals associated with each estimate were applied using `geom_errorbar`. Cities are ordered in increasing OR estimates of unsolved homicides, comparing male to female victims. 

```{r}
homicide_data_analysis %>% 
  ggplot(aes(x = reorder(city_state, odds_ratio), y = odds_ratio, color = city_state)) + 
  geom_point() +
  geom_errorbar(aes(ymin = lower_CI, ymax = upper_CI)) +
  labs(
    title = "City-Level Odds Ratio Estimates and 95% CIs for Unsolved Homicides Comparing Male to Female Victims", 
    x = "City, State", 
    y = "Odds Ratio Estimate") + 
  theme(
    axis.text.x = element_text(angle = 70, hjust = 1), 
    legend.position = "none")
```

# Problem 3 

## 3.1 Birth Weight Data Import and Cleaning

Let us begin by importing the CSV file containing birth weight data, and applying the `clean_names` function. The following variables were converted from numeric to factor variables to reflect the information in the codebook: `babysex`, `frace`, `malform`, and `mrace`. Labels were applied to these newly converted factor variables to improve readability of these data. Please note that although the provided codebook indicated that the `frace` and `mrace` variables had 6 and 5 possible values, respectively, the actual data set only contained 5 and 4 possible values for each variable respectively. More specifically, `frace` did not have any entries with 9 = Unknown, and `mrace` did not have any entries with 8 = Other. As such, these labels were omitted in the labeling process. The `fincome` variable, denoting family monthly income, was also modified to reflect the actual reported amounts (i.e., hundreds). Finally, the `skim` function was applied to generate a summary of the variables in the data set. 

```{r}
birthweight_data = 
  read_csv("./birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(babysex = factor(babysex, labels = c("Male", "Female")),
         fincome = fincome * 100, 
         frace = factor(frace, labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
         malform = factor(malform, labels = c("Absent", "Present")),
         mrace = factor(mrace, labels = c("White", "Black", "Asian", "Puerto Rican")))

skimr::skim(birthweight_data)
```

Based on the results from applying the `skim` function, there are no missing values for any variable in the data set. 

## 3.2 Birth Weight Data Analysis: Modeling Exercise

#### _Hypothesizing a Regression Model for Birth Weight_

According to the CDC, about 20% of babies born to mothers who smoke during their pregnancy are born with low birth weight (2020). Furthermore, existing literature has found increased maternal age to be a risk factor for low birth weight (Zheng et al., 2016). As such, we hypothesize that birth weight has an inverse linear relationship with the average number of cigarettes smoked per day during pregnancy (variable `smoken`) and maternal age (variable `momage`). Below, we fit this hypothesized model, and depict a plot of model residuals against fitted values using `add_residuals` and `add_predictions`. 

```{r}
birthweight_smoken_momage_fit = lm(bwt ~ momage + smoken, data = birthweight_data)

birthweight_smoken_momage_fit %>% 
  broom::tidy() %>% 
  knitr::kable(col.names = c('Term', 'Estimate', 'Standard Error', 'Statistic', 'p-value'), digits = 3)

birthweight_data_df = birthweight_data %>% 
  mutate(modelr::add_residuals(birthweight_data, birthweight_smoken_momage_fit), 
         modelr::add_predictions(birthweight_data, birthweight_smoken_momage_fit))

birthweight_data_df %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point()
```

#### _Fitting Comparison Models_

In subsequent analysis, we will compare the hypothesized model described above with the following 2 models:

(1) One using length at birth (`blength`) and gestational age (`gaweeks`) as predictors (main effects only); and
(1) One using head circumference (`bhead`), length (`blength`), sex (`babysex`), and all interactions (including the three-way interaction) between these. 

These two comparison models are fitted below in the following code. 

```{r}
birthweight_blength_gaweeks_fit = lm(bwt ~ blength + gaweeks, data = birthweight_data)

birthweight_bhead_blength_sex_fit = lm(bwt ~ (bhead + blength + babysex)^4, data = birthweight_data)
```

#### _Comparing Regression Models: Cross-Validated Prediction Error_

We can now perform a comparison between the three models in terms of cross-validated prediction error. To do this, we first create a cross-validation data frame `cv_df`. Contained within `cv_df` is 2 side-by-side list columns with the testing and training data split pairs, with a corresponding ID number for each pair. Since we are able to apply resample objects directly into `lm` functions, we can skip the extra step of converting the testing and training data into tibbles. Next, we apply the `map` function to map each regression model to the training data. Finally, we can compute the root mean squared errors (RMSEs) for each model by applying the `map2_dbl` function to the testing data. 

```{r}
cv_df = 
  crossv_mc(birthweight_data_df, 100)

cv_df = cv_df %>% 
  mutate(
    smoke_momage_mod      = map(.x = train, ~lm(bwt ~ momage + smoken, data = .x)), 
    blength_gaweeks_mod   = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)), 
    bhead_blength_sex_mod = map(.x = train, ~lm(bwt ~ (bhead + blength + babysex)^4, data = .x))) %>% 
  mutate(
    rmse_smoke_momage      = map2_dbl(.x = smoke_momage_mod, .y = test, ~rmse(model = .x, data = .y)), 
    rmse_blength_gaweeks   = map2_dbl(.x = blength_gaweeks_mod, .y = test, ~rmse(model = .x, data = .y)), 
    rmse_bhead_blength_sex = map2_dbl(.x = bhead_blength_sex_mod, .y = test, ~rmse(model = .x, data = .y)))
```

Using the output from the code above, we can see which of the three models is the best fit for birth weight data by plotting the distribution of RMSEs generated from each model. This process involves first tidying the data using `pivot_longer`, then using `ggplot` and `geom_violin` to generate a violin plot. 

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(), 
    names_to = "model", 
    values_to = "rmse", 
    names_prefix = "rmse_") %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin() + 
  labs(
    title = "Root Mean Squared Errors Distributions for Fitted Birth Weight Models", 
    x = "Fitted Model", 
    y = "RMSE") +
  scale_x_discrete(labels = c("bhead_blength_sex" = "Head Circ, Length, Sex Model", 
                              "blength_gaweeks" = "Length, Gestational Age Model", 
                              "smoke_momage" = "Smoke, Maternal Age Model"))
```

Based on the distributions depicted above, we can conclude that the model with head circumference, length, sex and all interactions between those variables is able to generate better predictions than the model with length and gestational age, and the model with smoking and maternal age. Having said that, however, due to the very large RMSEs generated from all three fitted models, none of the three generate especially accurate predictions on birth weight. This is likely due to the fact that birth weight is affected by a myriad of factors that were unable to be captured in the three models above. Such factors include, but are certainly not limited to, environmental determinants, genetic predispositions, and pregnancy diet. In order to generate a better fitted model to predict birth weight, several additional predictors should be included in future analyses. 

## References

CDC. (2020, April 28). Smoking during pregnancy. Centers for Disease Control and Prevention. Retrieved December 1, 2022, from https://www.cdc.gov/tobacco/basic_information/health_effects/pregnancy/index.htm#:~:text=Health%20Effects%20of%20Smoking%20and%20Secondhand%20Smoke%20on%20Babies&amp;text=One%20in%20every%20five%20babies,early%20are%20not%20as%20healthy. 

Zheng, W., Suzuki, K., Tanaka, T., Kohama, M., Yamagata, Z., & Okinawa Child Health Study Group (2016). Association between Maternal Smoking during Pregnancy and Low Birthweight: Effects by Maternal Age. PloS one, 11(1), e0146241. https://doi.org/10.1371/journal.pone.0146241

